{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de M15 Pr√°cticas 1, 2 y 3-Jos√© Savi√±√≥n",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoGANzaqvtXU"
      },
      "source": [
        "# Conditioning to classes\n",
        "\n",
        "En concreto deber√°s de crear una *red generativa condicionada* de la que puedas obtener im√°genes para cada una de las clases del dataset. Una vez lo hayas entrenado, visualiza la generaci√≥n de 3 im√°genes de la clase RANA (üê∏) y 3 im√°genes de la clase CABALLO (üêé). **Dada la complejidad del dataset y la poca resoluci√≥n de las im√°genes es normal esperar im√°genes donde se identifique claramente el objeto generado.**\n",
        "\n",
        "<br>\n",
        "<img src='https://miro.medium.com/max/424/1*0hHJfc0V_Km_AgKkP892fw.png'>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkfN2qs8v2DI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ac6f78-02e6-4bf0-ca32-34ccc0ffc94f"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "# Cargamos el dataset CIFAR10 en un variable.\n",
        "(X_train, Y_train), (X_test, Y_test) = load_data()\n",
        "\n",
        "# Normalizamos el input.\n",
        "X_train = X_train / 255\n",
        "X_test  = X_test  / 255\n",
        "\n",
        "# Codificamos One-Hot el output.\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test  = to_categorical(Y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre de las clases ordenadas por el √≠ndice correspondiente.\n",
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "metadata": {
        "id": "qinfmlezslfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionamos un √≠ndice aleatorio.\n",
        "idx = np.random.randint(0, 5000)\n",
        "# Visualizamos una de las im√°genes.\n",
        "plt.imshow(X_train[idx])\n",
        "plt.title(class_names[np.argmax(Y_train[idx])])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Rx6qZf86sm0-",
        "outputId": "8caa27ef-a088-48b1-ba17-47ed21560cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTRUCCI√ìN DEL MODELO\n",
        "#Modelo del discriminador\n",
        "latent_dim  = 128\n",
        "image_size  = 32\n",
        "num_classes = 10\n",
        "\n",
        "def get_discriminator():\n",
        "  #Creamos el discriminador\n",
        "  discriminator = Sequential(name = \"discriminator\")\n",
        "\n",
        "  discriminator.add(Input(shape=(image_size, image_size, 3 + num_classes)))\n",
        "\n",
        "  discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "  discriminator.add(BatchNormalization())\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  discriminator.add(Conv2D(128, kernel_size=4))\n",
        "  discriminator.add(BatchNormalization())\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  discriminator.add(Conv2D(128, kernel_size=4))\n",
        "  discriminator.add(BatchNormalization())\n",
        "  discriminator.add(LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  discriminator.add(GlobalMaxPooling2D())\n",
        "  discriminator.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "  discriminator.summary()\n",
        "  return discriminator\n",
        "\n",
        "get_discriminator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94nNabKlsoJx",
        "outputId": "f7c52700-64ed-4c8a-cda4-5e285d71e0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_94 (Conv2D)          (None, 16, 16, 64)        13376     \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 13, 13, 128)       131200    \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 13, 13, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 10, 10, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_96 (Bat  (None, 10, 10, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 128)              0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 408,257\n",
            "Trainable params: 407,617\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7fe3f5570a50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo del generador\n",
        "\n",
        "\n",
        "def get_generator(latent_dim=128):\n",
        "\n",
        "  generator = Sequential(name=\"generator\")\n",
        "  \n",
        "  # üí° >>> Ahora el input recibe el vector latente y el\n",
        "  #        vector One-hot concatenado.\n",
        "  generator.add(Input(shape=(latent_dim + num_classes)))\n",
        "  \n",
        "  generator.add(Dense(2 * 2 * latent_dim))\n",
        "  generator.add(Reshape((2, 2, latent_dim)))\n",
        "\n",
        "  generator.add(Conv2DTranspose(128, kernel_size=4, strides=4))\n",
        "  generator.add(BatchNormalization())\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  generator.add(Conv2DTranspose(512, kernel_size=4, strides=4, padding=\"valid\"))\n",
        "  generator.add(BatchNormalization())\n",
        "  generator.add(LeakyReLU(alpha=0.2))\n",
        "  \n",
        "  generator.add(Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"))\n",
        "\n",
        "  generator.summary()\n",
        "  return generator\n",
        "\n",
        "get_generator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVAkoxfwspst",
        "outputId": "29b03221-6299-4240-c235-c0bd0927a165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 512)               71168     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 128)        262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 512)      1049088   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 32, 32, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 32, 32, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,423,491\n",
            "Trainable params: 1,422,211\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7fe3f5094d90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, discriminator, generator, latent_dim):\n",
        "      super(GAN, self).__init__()\n",
        "      # Guardamos el discriminador y el generador.\n",
        "      self.discriminator = discriminator\n",
        "      self.generator     = generator\n",
        "      self.latent_dim    = latent_dim\n",
        "\n",
        "  def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "    super(GAN, self).compile(d_optimizer, g_optimizer, loss_fn)\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "  \n",
        "  def train_step(self, data):\n",
        "\n",
        "    # üí° >>> Ahora los datos son el input y las etiquetas.\n",
        "    real_images, one_hot_labels = data\n",
        "\n",
        "    # üí° >>> Formateamos el vector One-hot a tama√±o de imagen.\n",
        "    image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
        "    image_one_hot_labels = tf.repeat(image_one_hot_labels, repeats=[image_size * image_size])\n",
        "    image_one_hot_labels = tf.reshape(image_one_hot_labels, (-1, image_size, image_size, num_classes))\n",
        "\n",
        "    # ----------- ENTRENAMIENTO DEL DETECTOR ------------- #\n",
        "\n",
        "    # Tama√±o del lote.\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "    # Generamos vectores aleatorios como input de la red generadora.\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "     # üí° >>> A√±adimos la info de la clase a los vectores de entrada del generador.\n",
        "    random_latent_vectors = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
        "\n",
        "    # Usamos los vectores para generar im√°genes aleatorias. (Decodificamos)\n",
        "    fake_images = self.generator(random_latent_vectors)\n",
        "\n",
        "    # üí° >>> A√±adimos la info de la clase a las im√°genes de entrada del decodificador.\n",
        "    fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
        "    real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
        "\n",
        "    # Las concatenamos al set de im√°genes reales.\n",
        "    combined_images = tf.concat([real_image_and_labels, fake_image_and_labels], axis=0)\n",
        "\n",
        "    # Generamos el output para cada imagen (Real: 1 / Fake: 0)\n",
        "    labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
        "\n",
        "    # Add random noise to the labels - important trick!\n",
        "    labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # Predicciones hechas por el discrminador.\n",
        "      predictions = self.discriminator(combined_images)\n",
        "\n",
        "      # Evaluamos con la funci√≥n de coste los resultados del discriminador.\n",
        "      d_loss = self.loss_fn(labels, predictions)\n",
        "\n",
        "    # Calculamos el gradiente con el error del discriminador.\n",
        "    grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "\n",
        "    # Actualizamos los par√°metros con los gradientes.\n",
        "    self.d_optimizer.apply_gradients(\n",
        "          zip(grads, self.discriminator.trainable_weights)\n",
        "    )\n",
        "\n",
        "    # ----------- ENTRENAMIENTO DEL GENERADOR ------------- #\n",
        "\n",
        "    # Creamos nuevos vectores para generar im√°genes aleatorias. (Decodificamos)\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "    # Creamos las etiquetas con las que supervisar el entrenamiento del generador.\n",
        "    misleading_labels = tf.ones((batch_size, 1))\n",
        "\n",
        "    # Entrenamos al generador SIN actualizar al detector!\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # üí° >>> A√±adimos la info de la clase a los vectores de entrada del generador.\n",
        "      random_latent_vectors = tf.concat([random_latent_vectors, one_hot_labels], axis=1)\n",
        "\n",
        "      # üí° >>> Generamos y a√±adimos la info de las clases.\n",
        "      fake_images = self.generator(random_latent_vectors)\n",
        "      fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
        "\n",
        "      # Obtenemos nuevas predicciones pas√°ndole al discriminador lo generado.\n",
        "      predictions = self.discriminator(fake_image_and_labels)\n",
        "\n",
        "      # Calculamos el error del generador en su tarea de confundir al discriminador.\n",
        "      g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "\n",
        "    # Calculamos el gradiente del generador.\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "\n",
        "    # Actualizamos los par√°metros con los gradientes.\n",
        "    self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "    return {}"
      ],
      "metadata": {
        "id": "HRAS1aqXsrO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# üí° >>> Generamos el ImageDataGenerator.\n",
        "train_gen = ImageDataGenerator().flow(X_train.reshape(-1, 32, 32, 3), Y_train)"
      ],
      "metadata": {
        "id": "u7-3DaVfss8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# üí° >>> Creamos un callback personalizado para visualizar la evoluci√≥n\n",
        "# del generador tras cada √©poca.\n",
        "class GANMonitor1(Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(shape=(3, self.model.latent_dim))\n",
        "        # Generamos siempre vectores d la clase frog.\n",
        "        one_hot_vectors1 = tf.reshape(tf.repeat(to_categorical(6, num_classes=10)[None,:], repeats=3, axis=0), (3, num_classes))\n",
        "       \n",
        "        generated_image = self.model.generator(tf.concat([random_latent_vectors, one_hot_vectors1], axis=1))\n",
        "\n",
        "        fig, axs = plt.subplots(1, 3)\n",
        "\n",
        "        for i in range(3):\n",
        "          if generated_image.shape[3] > 1:\n",
        "            fig.axes[i].imshow(generated_image[i,:,:,:])\n",
        "            fig.axes[i].axis(\"off\")\n",
        "          else:\n",
        "            fig.axes[i].matshow(generated_image[i,:,:,0])\n",
        "            fig.axes[i].axis(\"off\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "class GANMonitor2(Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        random_latent_vectors = tf.random.normal(shape=(3, self.model.latent_dim))\n",
        "        # Generamos siempre vectores de la clase horse.\n",
        "        one_hot_vectors1 = tf.reshape(tf.repeat(to_categorical(7, num_classes=10)[None,:], repeats=3, axis=0), (3, num_classes))\n",
        "       \n",
        "        generated_image = self.model.generator(tf.concat([random_latent_vectors, one_hot_vectors1], axis=1))\n",
        "\n",
        "        fig, axs = plt.subplots(1, 3)\n",
        "\n",
        "        for i in range(3):\n",
        "          if generated_image.shape[3] > 1:\n",
        "            fig.axes[i].imshow(generated_image[i,:,:,:])\n",
        "            fig.axes[i].axis(\"off\")\n",
        "          else:\n",
        "            fig.axes[i].matshow(generated_image[i,:,:,0])\n",
        "            fig.axes[i].axis(\"off\")\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "qyu6cOqIsuLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.losses import *\n",
        "\n",
        "# Creamos una GAN con nuestra clase.\n",
        "gan = GAN(discriminator=get_discriminator(), generator=get_generator(), latent_dim=latent_dim)\n",
        "\n",
        "# Configuramos los optimizadores de cada parte...\n",
        "gan.compile(d_optimizer=Adam(learning_rate=0.0005),\n",
        "            g_optimizer=Adam(learning_rate=0.0005),\n",
        "            loss_fn=BinaryCrossentropy())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyVPFOOTsveo",
        "outputId": "10e401de-bc4a-4805-d95f-a28f623c6a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_98 (Conv2D)          (None, 16, 16, 64)        13376     \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 13, 13, 128)       131200    \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  (None, 13, 13, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 10, 10, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 10, 10, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 10, 10, 128)       0         \n",
            "                                                                 \n",
            " global_max_pooling2d_1 (Glo  (None, 128)              0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 408,257\n",
            "Trainable params: 407,617\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 512)               71168     \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 8, 8, 128)        262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_102 (Ba  (None, 8, 8, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 512)      1049088   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_103 (Ba  (None, 32, 32, 512)      2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 32, 32, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,423,491\n",
            "Trainable params: 1,422,211\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gan.fit(train_gen, epochs=1000, batch_size = 8, callbacks=[GANMonitor1(), GANMonitor2()], steps_per_epoch=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wkqg38GFsx8v",
        "outputId": "39ad8086-dc6e-4a70-9c6e-36596fbf17c1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}